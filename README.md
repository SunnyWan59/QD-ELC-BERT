# QD-ELC-BERT
My own implementation of the babyLM ELC BERT, given by the 2023 paper "Not all layers are equally as important: Every Layer Counts BERT" by Charpentier and Samuel
